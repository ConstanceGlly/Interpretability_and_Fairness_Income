{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading dataset using panda\n",
    "data_path = os.path.dirname(os.getcwd())\n",
    "data_df = pd.read_csv(os.path.join(data_path, \"data\\\\data_income.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target\n",
    "X = data_df.drop([\"income\"], axis=1)\n",
    "y = data_df[\"income\"]\n",
    "\n",
    "# Define the categorical columns to one-hot encode\n",
    "categorical_cols = [\n",
    "    \"occupation\",\n",
    "    \"education\",\n",
    "    \"workclass\",\n",
    "    \"marital-status\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"native-country\",\n",
    "    \"gender\",\n",
    "]\n",
    "numeric_cols = [\n",
    "    \"age\",\n",
    "    \"fnlwgt\",\n",
    "    \"educational-num\",\n",
    "    \"capital-gain\",\n",
    "    \"capital-loss\",\n",
    "    \"hours-per-week\",\n",
    "]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the format for y\n",
    "y_train = y_train.replace({\">50K\": 1, \"<=50K\": 0})\n",
    "y_test = y_test.replace({\">50K\": 1, \"<=50K\": 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8775\n"
     ]
    }
   ],
   "source": [
    "# Define preprocessing for categorical and numeric data\n",
    "categorical_preprocessor = OneHotEncoder()\n",
    "numeric_preprocessor = StandardScaler()\n",
    "\n",
    "# Create a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", categorical_preprocessor, categorical_cols),\n",
    "        (\"num\", numeric_preprocessor, numeric_cols),\n",
    "    ],\n",
    "    remainder=\"passthrough\",  # You can use this to include any remaining columns\n",
    ")\n",
    "\n",
    "# Create a pipeline with preprocessing and the machine learning model\n",
    "model = XGBClassifier(random_state=42)\n",
    "\n",
    "pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "# Fit the pipeline (including preprocessing) to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "# Make predictions on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot de l'accuracy par genre et couleur de peau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Global      Male   Female     White     Black\n",
      "Accuracy  0.87747  0.844724  0.94291  0.870053  0.935103\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculer l'accuracy par genre\n",
    "accuracy_par_genre = {}\n",
    "genres = ['Male', 'Female']\n",
    "for genre in genres:\n",
    "    mask_genre = X_test['gender'] == genre\n",
    "    accuracy_genre = accuracy_score(y_test[mask_genre], y_pred[mask_genre])\n",
    "    accuracy_par_genre[genre] = accuracy_genre\n",
    "\n",
    "# Calculer l'accuracy par race\n",
    "accuracy_par_race = {}\n",
    "races = ['White', 'Black']\n",
    "for race in races:\n",
    "    mask_race = X_test['race'] == race\n",
    "    accuracy_race = accuracy_score(y_test[mask_race], y_pred[mask_race])\n",
    "    accuracy_par_race[race] = accuracy_race\n",
    "\n",
    "# Créer un tableau double entrée avec les accuracies\n",
    "tableau_accuracies = pd.DataFrame({\n",
    "    'Global': accuracy,\n",
    "    'Male': accuracy_par_genre['Male'],\n",
    "    'Female': accuracy_par_genre['Female'],\n",
    "    'White': accuracy_par_race['White'],\n",
    "    'Black': accuracy_par_race['Black']\n",
    "}, index=['Accuracy'])\n",
    "\n",
    "print(tableau_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical Parity Test Homme / Femme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the format for y\n",
    "data_df['income'] = data_df['income'].replace({\">50K\": 1, \"<=50K\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser le DataFrame en deux groupes en fonction du genre\n",
    "group1 = data_df[data_df['gender'] == 'Male']\n",
    "group2 = data_df[data_df['gender'] == 'Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parité statistique - Proportion de prédictions positives pour homme : 0.3037672281776417\n",
      "Parité statistique - Proportion de prédictions positives pour femme : 0.10925148221343874\n"
     ]
    }
   ],
   "source": [
    "# Parité statistique : Comparer les proportions de prédictions positives entre les groupes\n",
    "prop_group1_positive = group1['income'].mean()\n",
    "prop_group2_positive = group2['income'].mean()\n",
    "\n",
    "# Afficher les résultats\n",
    "print(f\"Parité statistique - Proportion de prédictions positives pour homme : {prop_group1_positive}\")\n",
    "print(f\"Parité statistique - Proportion de prédictions positives pour femme : {prop_group2_positive}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 1]\n",
      "chi2 = 4686.750440209035\n",
      "Pas de preuve significative de violation de la parité statistique.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Données d'exemple (à remplacer par vos propres données)\n",
    "group1_predictions = pipeline.predict(group1.drop([\"income\"], axis=1))\n",
    "group2_predictions = pipeline.predict(group2.drop([\"income\"], axis=1))\n",
    "\n",
    "print(group1_predictions)\n",
    "print(group2_predictions)\n",
    "\n",
    "# Ajuster la taille des groupes\n",
    "min_length = min(len(group1_predictions), len(group2_predictions))\n",
    "group1_predictions = group1_predictions[:min_length]\n",
    "group2_predictions = np.random.choice(group2_predictions, min_length, replace=False)\n",
    "\n",
    "# Convertir les données en float64\n",
    "group1_predictions = group1_predictions.astype(np.float64)\n",
    "group2_predictions = group2_predictions.astype(np.float64)\n",
    "\n",
    "# Ajouter une petite constante aux données pour éviter les fréquences nulles\n",
    "epsilon = 1e-10\n",
    "group1_predictions += epsilon\n",
    "group2_predictions += epsilon\n",
    "\n",
    "# Créer un tableau de contingence\n",
    "contingency_table = np.array([group1_predictions, group2_predictions])\n",
    "\n",
    "# Effectuer le test du chi-carré\n",
    "chi2, p, _, _ = chi2_contingency(contingency_table, correction=True)\n",
    "\n",
    "# Interpréter le résultat\n",
    "print(f\"chi2 = {chi2}\")\n",
    "if p < 0.05:\n",
    "    print(\"La parité statistique n'est pas respectée.\")\n",
    "else:\n",
    "    print(\"Pas de preuve significative de violation de la parité statistique.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional Statistical Parity Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions de group1_predictions: (16192,)\n",
      "Dimensions de group2_predictions: (16192,)\n",
      "Dimensions de group1_positives: (1769,)\n",
      "Dimensions de group2_positives: (1769,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\matha\\OneDrive\\Documents\\HEC\\Cours\\Algorithmic Fairness and Interpretability\\Interpretability_and_Fairness_Income\\Notebooks\\Model Fairness.ipynb Cell 13\u001b[0m line \u001b[0;36m<cell line: 27>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matha/OneDrive/Documents/HEC/Cours/Algorithmic%20Fairness%20and%20Interpretability/Interpretability_and_Fairness_Income/Notebooks/Model%20Fairness.ipynb#X23sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDimensions de group2_positives:\u001b[39m\u001b[39m\"\u001b[39m, group2_positives\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matha/OneDrive/Documents/HEC/Cours/Algorithmic%20Fairness%20and%20Interpretability/Interpretability_and_Fairness_Income/Notebooks/Model%20Fairness.ipynb#X23sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# Créer un DataFrame pour faciliter l'échantillonnage\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/matha/OneDrive/Documents/HEC/Cours/Algorithmic%20Fairness%20and%20Interpretability/Interpretability_and_Fairness_Income/Notebooks/Model%20Fairness.ipynb#X23sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m df_group1 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame({\u001b[39m'\u001b[39;49m\u001b[39mpredictions\u001b[39;49m\u001b[39m'\u001b[39;49m: group1_predictions, \u001b[39m'\u001b[39;49m\u001b[39mpositives\u001b[39;49m\u001b[39m'\u001b[39;49m: group1_positives})\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matha/OneDrive/Documents/HEC/Cours/Algorithmic%20Fairness%20and%20Interpretability/Interpretability_and_Fairness_Income/Notebooks/Model%20Fairness.ipynb#X23sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m df_group2 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39mpredictions\u001b[39m\u001b[39m'\u001b[39m: group2_predictions, \u001b[39m'\u001b[39m\u001b[39mpositives\u001b[39m\u001b[39m'\u001b[39m: group2_positives})\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matha/OneDrive/Documents/HEC/Cours/Algorithmic%20Fairness%20and%20Interpretability/Interpretability_and_Fairness_Income/Notebooks/Model%20Fairness.ipynb#X23sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# Afficher les dimensions après avoir créé les DataFrames\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matha\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    727\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    728\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    729\u001b[0m     )\n\u001b[0;32m    731\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    732\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    734\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    735\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m \u001b[39mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\matha\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\matha\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    115\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\matha\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(lengths) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll arrays must be of the same length\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[39mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# Extraire les données nécessaires\n",
    "group1_predictions = data_df[data_df['gender'] == 'Male']['income'].values\n",
    "group2_predictions = data_df[data_df['gender'] == 'Female']['income'].values\n",
    "group1_positives = data_df[(data_df['gender'] == 'Male') & (data_df['income'] == 1)]['income'].values\n",
    "group2_positives = data_df[(data_df['gender'] == 'Female') & (data_df['income'] == 1)]['income'].values\n",
    "protected_attribute = data_df['gender'].values\n",
    "\n",
    "# Ajuster la taille des groupes\n",
    "min_length = min(len(group1_predictions), len(group2_predictions))\n",
    "group1_predictions = group1_predictions[:min_length]\n",
    "group2_predictions = group2_predictions[:min_length]  # Ajuster ici\n",
    "group1_positives = group1_positives[:min_length]\n",
    "group2_positives = group2_positives[:min_length]  # Ajuster ici\n",
    "\n",
    "# Ajuster la taille des groupes de prédictions positives\n",
    "min_positives_length = min(len(group1_positives), len(group2_positives))\n",
    "group1_positives = group1_positives[:min_positives_length]\n",
    "group2_positives = group2_positives[:min_positives_length]\n",
    "\n",
    "# Afficher les dimensions après ajustement\n",
    "print(\"Dimensions de group1_predictions:\", group1_predictions.shape)\n",
    "print(\"Dimensions de group2_predictions:\", group2_predictions.shape)\n",
    "print(\"Dimensions de group1_positives:\", group1_positives.shape)\n",
    "print(\"Dimensions de group2_positives:\", group2_positives.shape)\n",
    "\n",
    "# Créer un DataFrame pour faciliter l'échantillonnage\n",
    "df_group1 = pd.DataFrame({'predictions': group1_predictions, 'positives': group1_positives})\n",
    "df_group2 = pd.DataFrame({'predictions': group2_predictions, 'positives': group2_positives})\n",
    "\n",
    "# Afficher les dimensions après avoir créé les DataFrames\n",
    "print(\"Dimensions de df_group1:\", df_group1.shape)\n",
    "print(\"Dimensions de df_group2:\", df_group2.shape)\n",
    "\n",
    "# Échantillonner aléatoirement sans remplacement pour égaliser la taille\n",
    "df_group2 = df_group2.sample(min_length, replace=False, random_state=42)\n",
    "\n",
    "# Extraire les données égalisées\n",
    "group1_predictions = df_group1['predictions'].values\n",
    "group2_predictions = df_group2['predictions'].values\n",
    "group1_positives = df_group1['positives'].values\n",
    "group2_positives = df_group2['positives'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\matha\\OneDrive\\Documents\\HEC\\Cours\\Algorithmic Fairness and Interpretability\\Interpretability_and_Fairness_Income\\Notebooks\\Model Fairness.ipynb Cell 13\u001b[0m line \u001b[0;36m<cell line: 27>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matha/OneDrive/Documents/HEC/Cours/Algorithmic%20Fairness%20and%20Interpretability/Interpretability_and_Fairness_Income/Notebooks/Model%20Fairness.ipynb#X22sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m group2_predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(group2_predictions, min_length, replace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matha/OneDrive/Documents/HEC/Cours/Algorithmic%20Fairness%20and%20Interpretability/Interpretability_and_Fairness_Income/Notebooks/Model%20Fairness.ipynb#X22sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m group2_positives \u001b[39m=\u001b[39m group2_positives[:min_length]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/matha/OneDrive/Documents/HEC/Cours/Algorithmic%20Fairness%20and%20Interpretability/Interpretability_and_Fairness_Income/Notebooks/Model%20Fairness.ipynb#X22sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m group1_positives \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mchoice(group1_positives, min_length, replace\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matha/OneDrive/Documents/HEC/Cours/Algorithmic%20Fairness%20and%20Interpretability/Interpretability_and_Fairness_Income/Notebooks/Model%20Fairness.ipynb#X22sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Afficher les dimensions des données égalisées\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matha/OneDrive/Documents/HEC/Cours/Algorithmic%20Fairness%20and%20Interpretability/Interpretability_and_Fairness_Income/Notebooks/Model%20Fairness.ipynb#X22sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDimensions des données égalisées :\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mnumpy\\\\random\\\\mtrand.pyx:1000\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "# Séparer les données en groupes\n",
    "group1_data = data_df[data_df['gender'] == 'Male']\n",
    "group2_data = data_df[data_df['gender'] == 'Female']\n",
    "\n",
    "# Trouver le groupe avec la taille la plus petite\n",
    "min_group_size = min(len(group1_data), len(group2_data))\n",
    "\n",
    "# Échantillonner aléatoirement le groupe plus grand pour égaler la taille\n",
    "group1_data = group1_data.sample(min_group_size, replace=False, random_state=42)\n",
    "group2_data = group2_data.sample(min_group_size, replace=False, random_state=42)\n",
    "\n",
    "# Concaténer les groupes équilibrés\n",
    "data_df = pd.concat([group1_data, group2_data])\n",
    "\n",
    "# Extraire les données nécessaires\n",
    "group1_predictions = data_df[data_df['gender'] == 'Male']['income'].values\n",
    "group2_predictions = data_df[data_df['gender'] == 'Female']['income'].values\n",
    "group1_positives = data_df[(data_df['gender'] == 'Male') & (data_df['income'] == 1)]['income'].values\n",
    "group2_positives = data_df[(data_df['gender'] == 'Female') & (data_df['income'] == 1)]['income'].values\n",
    "protected_attribute = data_df['gender'].values\n",
    "\n",
    "# Ajuster la taille des groupes\n",
    "min_length = min(len(group1_predictions), len(group2_predictions))\n",
    "group1_predictions = group1_predictions[:min_length]\n",
    "group2_predictions = np.random.choice(group2_predictions, min_length, replace=False)\n",
    "group1_positives = group1_positives[:min_length]\n",
    "group2_positives = np.random.choice(group2_positives, min_length, replace=False)\n",
    "\n",
    "# Afficher les dimensions des données égalisées\n",
    "print(\"Dimensions des données égalisées :\")\n",
    "print(\"Group 1 Predictions:\", group1_predictions.shape)\n",
    "print(\"Group 2 Predictions:\", group2_predictions.shape)\n",
    "print(\"Group 1 Positives:\", group1_positives.shape)\n",
    "print(\"Group 2 Positives:\", group2_positives.shape)\n",
    "print(\"Protected Attribute:\", protected_attribute.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\matha\\OneDrive\\Documents\\HEC\\Cours\\Algorithmic Fairness and Interpretability\\Interpretability_and_Fairness_Income\\Notebooks\\Model Fairness.ipynb Cell 14\u001b[0m line \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/matha/OneDrive/Documents/HEC/Cours/Algorithmic%20Fairness%20and%20Interpretability/Interpretability_and_Fairness_Income/Notebooks/Model%20Fairness.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m chi2_contingency, chi2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/matha/OneDrive/Documents/HEC/Cours/Algorithmic%20Fairness%20and%20Interpretability/Interpretability_and_Fairness_Income/Notebooks/Model%20Fairness.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Créer un tableau de contingence conditionnelle\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/matha/OneDrive/Documents/HEC/Cours/Algorithmic%20Fairness%20and%20Interpretability/Interpretability_and_Fairness_Income/Notebooks/Model%20Fairness.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m contingency_table \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray([group1_predictions, group2_predictions, group1_positives, group2_positives])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/matha/OneDrive/Documents/HEC/Cours/Algorithmic%20Fairness%20and%20Interpretability/Interpretability_and_Fairness_Income/Notebooks/Model%20Fairness.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Effectuer le test de Mantel-Haenszel\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/matha/OneDrive/Documents/HEC/Cours/Algorithmic%20Fairness%20and%20Interpretability/Interpretability_and_Fairness_Income/Notebooks/Model%20Fairness.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m chi2, p, _, _ \u001b[39m=\u001b[39m chi2_contingency(contingency_table, lambda_\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlog-likelihood\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency, chi2\n",
    "\n",
    "# Créer un tableau de contingence conditionnelle\n",
    "contingency_table = np.array([group1_predictions, group2_predictions, group1_positives, group2_positives])\n",
    "\n",
    "# Effectuer le test de Mantel-Haenszel\n",
    "chi2, p, _, _ = chi2_contingency(contingency_table, lambda_=\"log-likelihood\")\n",
    "\n",
    "# Degré de liberté\n",
    "df = (contingency_table.shape[0] - 1) * (contingency_table.shape[1] - 1)\n",
    "\n",
    "# Calculer la valeur critique\n",
    "critical_value = chi2.ppf(0.95, df)\n",
    "\n",
    "# Interpréter le résultat\n",
    "if chi2 > critical_value:\n",
    "    print(\"La parité statistique conditionnelle n'est pas respectée.\")\n",
    "else:\n",
    "    print(\"Pas de preuve significative de violation de la parité statistique conditionnelle.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
