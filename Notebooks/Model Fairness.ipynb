{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading dataset using panda\n",
    "data_path = os.path.dirname(os.getcwd())\n",
    "data_df = pd.read_csv(os.path.join(data_path, \"data\\\\data_income.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target\n",
    "X = data_df.drop([\"income\"], axis=1)\n",
    "y = data_df[\"income\"]\n",
    "\n",
    "# Define the categorical columns to one-hot encode\n",
    "categorical_cols = [\n",
    "    \"occupation\",\n",
    "    \"education\",\n",
    "    \"workclass\",\n",
    "    \"marital-status\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"native-country\",\n",
    "    \"gender\",\n",
    "]\n",
    "numeric_cols = [\n",
    "    \"age\",\n",
    "    \"fnlwgt\",\n",
    "    \"educational-num\",\n",
    "    \"capital-gain\",\n",
    "    \"capital-loss\",\n",
    "    \"hours-per-week\",\n",
    "]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the format for y\n",
    "y_train = y_train.replace({\">50K\": 1, \"<=50K\": 0})\n",
    "y_test = y_test.replace({\">50K\": 1, \"<=50K\": 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8775\n"
     ]
    }
   ],
   "source": [
    "# Define preprocessing for categorical and numeric data\n",
    "categorical_preprocessor = OneHotEncoder()\n",
    "numeric_preprocessor = StandardScaler()\n",
    "\n",
    "# Create a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", categorical_preprocessor, categorical_cols),\n",
    "        (\"num\", numeric_preprocessor, numeric_cols),\n",
    "    ],\n",
    "    remainder=\"passthrough\",  # You can use this to include any remaining columns\n",
    ")\n",
    "\n",
    "# Create a pipeline with preprocessing and the machine learning model\n",
    "model = XGBClassifier(random_state=42)\n",
    "\n",
    "pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "# Fit the pipeline (including preprocessing) to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "# Make predictions on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot de l'accuracy par genre et couleur de peau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Global      Male   Female     White     Black\n",
      "Accuracy  0.87747  0.844724  0.94291  0.870053  0.935103\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculer l'accuracy par genre\n",
    "accuracy_par_genre = {}\n",
    "genres = ['Male', 'Female']\n",
    "for genre in genres:\n",
    "    mask_genre = X_test['gender'] == genre\n",
    "    accuracy_genre = accuracy_score(y_test[mask_genre], y_pred[mask_genre])\n",
    "    accuracy_par_genre[genre] = accuracy_genre\n",
    "\n",
    "# Calculer l'accuracy par race\n",
    "accuracy_par_race = {}\n",
    "races = ['White', 'Black']\n",
    "for race in races:\n",
    "    mask_race = X_test['race'] == race\n",
    "    accuracy_race = accuracy_score(y_test[mask_race], y_pred[mask_race])\n",
    "    accuracy_par_race[race] = accuracy_race\n",
    "\n",
    "# Créer un tableau double entrée avec les accuracies\n",
    "tableau_accuracies = pd.DataFrame({\n",
    "    'Global': accuracy,\n",
    "    'Male': accuracy_par_genre['Male'],\n",
    "    'Female': accuracy_par_genre['Female'],\n",
    "    'White': accuracy_par_race['White'],\n",
    "    'Black': accuracy_par_race['Black']\n",
    "}, index=['Accuracy'])\n",
    "\n",
    "print(tableau_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul des TPR (True positive rates) pour chaque catégorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Overall     Male    Female     White     Black\n",
      "True Positive Rate  0.676419  0.68932  0.600601  0.679101  0.596491\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculer la matrice de confusion pour chaque catégorie\n",
    "conf_matrix_overall = confusion_matrix(y_test, y_pred)\n",
    "conf_matrix_male = confusion_matrix(y_test[X_test['gender'] == 'Male'], y_pred[X_test['gender'] == 'Male'])\n",
    "conf_matrix_female = confusion_matrix(y_test[X_test['gender'] == 'Female'], y_pred[X_test['gender'] == 'Female'])\n",
    "conf_matrix_white = confusion_matrix(y_test[X_test['race'] == 'White'], y_pred[X_test['race'] == 'White'])\n",
    "conf_matrix_black = confusion_matrix(y_test[X_test['race'] == 'Black'], y_pred[X_test['race'] == 'Black'])\n",
    "\n",
    "# Calculer les taux de vrais positifs\n",
    "tp_rate_overall = conf_matrix_overall[1, 1] / (conf_matrix_overall[1, 1] + conf_matrix_overall[1, 0])\n",
    "tp_rate_male = conf_matrix_male[1, 1] / (conf_matrix_male[1, 1] + conf_matrix_male[1, 0])\n",
    "tp_rate_female = conf_matrix_female[1, 1] / (conf_matrix_female[1, 1] + conf_matrix_female[1, 0])\n",
    "tp_rate_white = conf_matrix_white[1, 1] / (conf_matrix_white[1, 1] + conf_matrix_white[1, 0])\n",
    "tp_rate_black = conf_matrix_black[1, 1] / (conf_matrix_black[1, 1] + conf_matrix_black[1, 0])\n",
    "\n",
    "# Créer un tableau double entrée avec les taux de vrais positifs\n",
    "tableau_tp_rates = pd.DataFrame({\n",
    "    'Overall': [tp_rate_overall],\n",
    "    'Male': [tp_rate_male],\n",
    "    'Female': [tp_rate_female],\n",
    "    'White': [tp_rate_white],\n",
    "    'Black': [tp_rate_black]\n",
    "}, index=['True Positive Rate'])\n",
    "\n",
    "# Afficher le tableau\n",
    "print(tableau_tp_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False negative rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Overall     Male    Female     White     Black\n",
      "False Negative Rate  0.323581  0.31068  0.399399  0.320899  0.403509\n"
     ]
    }
   ],
   "source": [
    "# Calculer les taux de faux négatifs\n",
    "fn_rate_overall = conf_matrix_overall[1, 0] / (conf_matrix_overall[1, 0] + conf_matrix_overall[1, 1])\n",
    "fn_rate_male = conf_matrix_male[1, 0] / (conf_matrix_male[1, 0] + conf_matrix_male[1, 1])\n",
    "fn_rate_female = conf_matrix_female[1, 0] / (conf_matrix_female[1, 0] + conf_matrix_female[1, 1])\n",
    "fn_rate_white = conf_matrix_white[1, 0] / (conf_matrix_white[1, 0] + conf_matrix_white[1, 1])\n",
    "fn_rate_black = conf_matrix_black[1, 0] / (conf_matrix_black[1, 0] + conf_matrix_black[1, 1])\n",
    "\n",
    "# Créer un tableau double entrée avec les taux de faux négatifs\n",
    "tableau_fn_rates = pd.DataFrame({\n",
    "    'Overall': [fn_rate_overall],\n",
    "    'Male': [fn_rate_male],\n",
    "    'Female': [fn_rate_female],\n",
    "    'White': [fn_rate_white],\n",
    "    'Black': [fn_rate_black]\n",
    "}, index=['False Negative Rate'])\n",
    "\n",
    "# Afficher le tableau\n",
    "print(tableau_fn_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intersection True Positive rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Overall  White Male  White Female  Black Male  \\\n",
      "True Positive Rate  0.676419     0.69098       0.60678    0.590909   \n",
      "\n",
      "                    Black Female  \n",
      "True Positive Rate      0.615385  \n"
     ]
    }
   ],
   "source": [
    "# Calculer la matrice de confusion pour chaque catégorie\n",
    "conf_matrix_overall = confusion_matrix(y_test, y_pred)\n",
    "conf_matrix_white_male = confusion_matrix(y_test[(X_test['gender'] == 'Male') & (X_test['race'] == 'White')], y_pred[(X_test['gender'] == 'Male') & (X_test['race'] == 'White')])\n",
    "conf_matrix_white_female = confusion_matrix(y_test[(X_test['gender'] == 'Female') & (X_test['race'] == 'White')], y_pred[(X_test['gender'] == 'Female') & (X_test['race'] == 'White')])\n",
    "conf_matrix_black_male = confusion_matrix(y_test[(X_test['race'] == 'Black') & (X_test['gender'] == 'Male')], y_pred[(X_test['race'] == 'Black') & (X_test['gender'] == 'Male')])\n",
    "conf_matrix_black_female = confusion_matrix(y_test[(X_test['race'] == 'Black') & (X_test['gender'] == 'Female')], y_pred[(X_test['race'] == 'Black') & (X_test['gender'] == 'Female')])\n",
    "\n",
    "# Calculer les taux de vrais positifs\n",
    "tp_rate_overall = conf_matrix_overall[1, 1] / (conf_matrix_overall[1, 1] + conf_matrix_overall[1, 0])\n",
    "tp_rate_white_male = conf_matrix_white_male[1, 1] / (conf_matrix_white_male[1, 1] + conf_matrix_white_male[1, 0])\n",
    "tp_rate_white_female = conf_matrix_white_female[1, 1] / (conf_matrix_white_female[1, 1] + conf_matrix_white_female[1, 0])\n",
    "tp_rate_black_male = conf_matrix_black_male[1, 1] / (conf_matrix_black_male[1, 1] + conf_matrix_black_male[1, 0])\n",
    "tp_rate_black_female = conf_matrix_black_female[1, 1] / (conf_matrix_black_female[1, 1] + conf_matrix_black_female[1, 0])\n",
    "\n",
    "# Créer un tableau double entrée avec les taux de vrais positifs\n",
    "tableau_tp_rates = pd.DataFrame({\n",
    "    'Overall': [tp_rate_overall],\n",
    "    'White Male': [tp_rate_white_male],\n",
    "    'White Female': [tp_rate_white_female],\n",
    "    'Black Male': [tp_rate_black_male],\n",
    "    'Black Female': [tp_rate_black_female]\n",
    "}, index=['True Positive Rate'])\n",
    "\n",
    "# Afficher le tableau\n",
    "print(tableau_tp_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taux de faux négatifs par groupes croisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Overall  White Male  White Female  Black Male  \\\n",
      "False Negative Rate  0.323581     0.30902       0.39322    0.409091   \n",
      "\n",
      "                     Black Female  \n",
      "False Negative Rate      0.384615  \n"
     ]
    }
   ],
   "source": [
    "# Calculer les taux de faux négatifs\n",
    "fn_rate_overall = conf_matrix_overall[1, 0] / (conf_matrix_overall[1, 0] + conf_matrix_overall[1, 1])\n",
    "fn_rate_white_male = conf_matrix_white_male[1, 0] / (conf_matrix_white_male[1, 0] + conf_matrix_white_male[1, 1])\n",
    "fn_rate_white_female = conf_matrix_white_female[1, 0] / (conf_matrix_white_female[1, 0] + conf_matrix_white_female[1, 1])\n",
    "fn_rate_black_male = conf_matrix_black_male[1, 0] / (conf_matrix_black_male[1, 0] + conf_matrix_black_male[1, 1])\n",
    "fn_rate_black_female = conf_matrix_black_female[1, 0] / (conf_matrix_black_female[1, 0] + conf_matrix_black_female[1, 1])\n",
    "\n",
    "# Créer un tableau double entrée avec les taux de faux négatifs\n",
    "tableau_fn_rates = pd.DataFrame({\n",
    "    'Overall': [fn_rate_overall],\n",
    "    'White Male': [fn_rate_white_male],\n",
    "    'White Female': [fn_rate_white_female],\n",
    "    'Black Male': [fn_rate_black_male],\n",
    "    'Black Female': [fn_rate_black_female]\n",
    "}, index=['False Negative Rate'])\n",
    "\n",
    "# Afficher le tableau\n",
    "print(tableau_fn_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Male & White  Male & Black  Female & White  \\\n",
      "True Positive Rate Intersection      0.333251      0.651376        0.082508   \n",
      "\n",
      "                                 Female & Black  \n",
      "True Positive Rate Intersection        0.447427  \n"
     ]
    }
   ],
   "source": [
    "# Calculer les taux de vrais positifs à l'intersection des groupes\n",
    "tp_rate_male_white = conf_matrix_male[1, 1] / (conf_matrix_male[1, 1] + conf_matrix_male[1, 0] + conf_matrix_white[1, 1] + conf_matrix_white[1, 0])\n",
    "tp_rate_male_black = conf_matrix_male[1, 1] / (conf_matrix_male[1, 1] + conf_matrix_male[1, 0] + conf_matrix_black[1, 1] + conf_matrix_black[1, 0])\n",
    "tp_rate_female_white = conf_matrix_female[1, 1] / (conf_matrix_female[1, 1] + conf_matrix_female[1, 0] + conf_matrix_white[1, 1] + conf_matrix_white[1, 0])\n",
    "tp_rate_female_black = conf_matrix_female[1, 1] / (conf_matrix_female[1, 1] + conf_matrix_female[1, 0] + conf_matrix_black[1, 1] + conf_matrix_black[1, 0])\n",
    "\n",
    "# Créer un tableau avec les taux de vrais positifs à l'intersection des groupes\n",
    "tableau_tp_rates_intersection = pd.DataFrame({\n",
    "    'Male & White': [tp_rate_male_white],\n",
    "    'Male & Black': [tp_rate_male_black],\n",
    "    'Female & White': [tp_rate_female_white],\n",
    "    'Female & Black': [tp_rate_female_black]\n",
    "}, index=['True Positive Rate Intersection'])\n",
    "\n",
    "# Afficher le tableau\n",
    "print(tableau_tp_rates_intersection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the format for y\n",
    "data_df['income'] = data_df['income'].replace({\">50K\": 1, \"<=50K\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical Parity Test : Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeur critique : 4.2460657987164824e-108\n",
      "chi2 : 486.6479284916249\n",
      "Il y a une disparité statistiquement significative par rapport au genre.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Créer un tableau de contingence pour le genre et la prédiction de revenu\n",
    "contingency_table = pd.crosstab(X_test['gender'], y_pred, margins=True)\n",
    "\n",
    "# Effectuer le test du chi-carré pour la parité statistique\n",
    "chi2, p, _, _ = chi2_contingency(contingency_table.iloc[:-1, :-1])\n",
    "\n",
    "# Calculer le degré de liberté\n",
    "df = (contingency_table.shape[0] - 1) * (contingency_table.shape[1] - 1)\n",
    "\n",
    "# Calculer la valeur critique à un niveau de signification donné (par exemple, 0,05)\n",
    "alpha = 0.05\n",
    "critical_value = chi2_contingency(contingency_table.iloc[:-1, :-1], correction=False)[1]\n",
    "print(\"Valeur critique :\", critical_value)\n",
    "print(\"chi2 :\", chi2)\n",
    "\n",
    "# Vérifier si la statistique du chi-carré est supérieure à la valeur critique\n",
    "if chi2 > critical_value:\n",
    "    print(\"Il y a une disparité statistiquement significative par rapport au genre.\")\n",
    "else:\n",
    "    print(\"Il n'y a pas de disparité statistiquement significative par rapport au genre.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical Parity Test : Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeur critique : 1.0401903751083985e-24\n",
      "chi2 : 118.64468203069983\n",
      "Il y a une disparité statistiquement significative par rapport à la couleur de peau.\n"
     ]
    }
   ],
   "source": [
    "# Faire des prédictions sur l'ensemble de test\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Créer un tableau de contingence pour le genre et la prédiction de revenu\n",
    "contingency_table = pd.crosstab(X_test['race'], y_pred, margins=True)\n",
    "\n",
    "# Effectuer le test du chi-carré pour la parité statistique\n",
    "chi2, p, _, _ = chi2_contingency(contingency_table.iloc[:-1, :-1])\n",
    "\n",
    "# Calculer le degré de liberté\n",
    "df = (contingency_table.shape[0] - 1) * (contingency_table.shape[1] - 1)\n",
    "\n",
    "# Calculer la valeur critique à un niveau de signification donné (par exemple, 0,05)\n",
    "alpha = 0.05\n",
    "critical_value = chi2_contingency(contingency_table.iloc[:-1, :-1], correction=False)[1]\n",
    "print(\"Valeur critique :\", critical_value)\n",
    "print(\"chi2 :\", chi2)\n",
    "\n",
    "# Vérifier si la statistique du chi-carré est supérieure à la valeur critique\n",
    "if chi2 > critical_value:\n",
    "    print(\"Il y a une disparité statistiquement significative par rapport à la couleur de peau.\")\n",
    "else:\n",
    "    print(\"Il n'y a pas de disparité statistiquement significative par rapport à la couleur de peau.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional Statistical Parity Test : Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2_values : {'Female': 1408.063091067341, 'Male': 2509.2967865810433}\n",
      "critical_value : 0.0\n",
      "La parité statistique conditionnelle n'est pas satisfaite.\n"
     ]
    }
   ],
   "source": [
    "# Créer un DataFrame combinant les vraies étiquettes, les étiquettes prédites et l'attribut protégé (gender)\n",
    "results_df = pd.DataFrame({'True_Labels': y_test, 'Predicted_Labels': y_pred, 'Gender': X_test['gender']})\n",
    "\n",
    "# Calculer les comptes conditionnels pour CSP\n",
    "csp_counts = results_df.groupby(['Gender', 'Predicted_Labels', 'True_Labels']).size().unstack(fill_value=0)\n",
    "\n",
    "# Effectuer le test du chi-carré pour chaque groupe de genre\n",
    "gender_groups = results_df['Gender'].unique()\n",
    "chi2_values = {}\n",
    "\n",
    "for gender_group in gender_groups:\n",
    "    sub_df = csp_counts.loc[gender_group]\n",
    "    chi2, p, _, _ = chi2_contingency(sub_df)\n",
    "    chi2_values[gender_group] = chi2\n",
    "\n",
    "# Calculer la valeur critique à un niveau de signification donné (par exemple, 0,05)\n",
    "alpha = 0.05\n",
    "df = (len(csp_counts.columns) - 1) * (len(csp_counts.index) - 1)\n",
    "\n",
    "critical_value = chi2_contingency(sub_df, correction=False)[1]\n",
    "\n",
    "# Vérifier si les statistiques du chi-carré pour tous les groupes de genre sont inférieures à la valeur critique\n",
    "csp_satisfied = all(chi2 <= critical_value for chi2 in chi2_values.values())\n",
    "\n",
    "print(\"chi2_values :\", chi2_values)\n",
    "print(\"critical_value :\", critical_value)\n",
    "\n",
    "if csp_satisfied:\n",
    "    print(\"La parité statistique conditionnelle est satisfaite.\")\n",
    "else:\n",
    "    print(\"La parité statistique conditionnelle n'est pas satisfaite.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional Statistical Parity Test : Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2_values : {'White': 3423.061150354326, 'Other': 42.119691509691506, 'Black': 415.19767509902806, 'Asian-Pac-Islander': 97.72081321054685, 'Amer-Indian-Eskimo': 19.919112218530824}\n",
      "critical_value : 1.8645325480191648e-07\n",
      "La parité statistique conditionnelle n'est pas satisfaite.\n"
     ]
    }
   ],
   "source": [
    "# Créer un DataFrame combinant les vraies étiquettes, les étiquettes prédites et l'attribut protégé (gender)\n",
    "results_df = pd.DataFrame({'True_Labels': y_test, 'Predicted_Labels': y_pred, 'Race': X_test['race']})\n",
    "\n",
    "# Calculer les comptes conditionnels pour CSP\n",
    "csp_counts = results_df.groupby(['Race', 'Predicted_Labels', 'True_Labels']).size().unstack(fill_value=0)\n",
    "\n",
    "# Effectuer le test du chi-carré pour chaque groupe de genre\n",
    "gender_groups = results_df['Race'].unique()\n",
    "chi2_values = {}\n",
    "\n",
    "for gender_group in gender_groups:\n",
    "    sub_df = csp_counts.loc[gender_group]\n",
    "    chi2, p, _, _ = chi2_contingency(sub_df)\n",
    "    chi2_values[gender_group] = chi2\n",
    "\n",
    "# Calculer la valeur critique à un niveau de signification donné (par exemple, 0,05)\n",
    "alpha = 0.05\n",
    "df = (len(csp_counts.columns) - 1) * (len(csp_counts.index) - 1)\n",
    "\n",
    "critical_value = chi2_contingency(sub_df, correction=False)[1]\n",
    "\n",
    "# Vérifier si les statistiques du chi-carré pour tous les groupes de genre sont inférieures à la valeur critique\n",
    "csp_satisfied = all(chi2 <= critical_value for chi2 in chi2_values.values())\n",
    "\n",
    "print(\"chi2_values :\", chi2_values)\n",
    "print(\"critical_value :\", critical_value)\n",
    "\n",
    "if csp_satisfied:\n",
    "    print(\"La parité statistique conditionnelle est satisfaite.\")\n",
    "else:\n",
    "    print(\"La parité statistique conditionnelle n'est pas satisfaite.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fairness Partial Dependance Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U5'), dtype('float64')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\matha\\OneDrive\\Documents\\HEC\\Cours\\Algorithmic Fairness and Interpretability\\Interpretability_and_Fairness_Income\\Notebooks\\Model Fairness.ipynb Cell 28\u001b[0m line \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/matha/OneDrive/Documents/HEC/Cours/Algorithmic%20Fairness%20and%20Interpretability/Interpretability_and_Fairness_Income/Notebooks/Model%20Fairness.ipynb#X52sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Définir la caractéristique d'intérêt et créer une grille de valeurs à analyser\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/matha/OneDrive/Documents/HEC/Cours/Algorithmic%20Fairness%20and%20Interpretability/Interpretability_and_Fairness_Income/Notebooks/Model%20Fairness.ipynb#X52sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m feature_of_interest \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mincome\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/matha/OneDrive/Documents/HEC/Cours/Algorithmic%20Fairness%20and%20Interpretability/Interpretability_and_Fairness_Income/Notebooks/Model%20Fairness.ipynb#X52sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m feature_values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlinspace(data_df[feature_of_interest]\u001b[39m.\u001b[39;49mmin(), data_df[feature_of_interest]\u001b[39m.\u001b[39;49mmax(), num\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matha/OneDrive/Documents/HEC/Cours/Algorithmic%20Fairness%20and%20Interpretability/Interpretability_and_Fairness_Income/Notebooks/Model%20Fairness.ipynb#X52sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Initialiser les listes pour stocker les mesures d'équité et l'exactitude du modèle\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matha/OneDrive/Documents/HEC/Cours/Algorithmic%20Fairness%20and%20Interpretability/Interpretability_and_Fairness_Income/Notebooks/Model%20Fairness.ipynb#X52sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m mesures_equite \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\function_base.py:129\u001b[0m, in \u001b[0;36mlinspace\u001b[1;34m(start, stop, num, endpoint, retstep, dtype, axis)\u001b[0m\n\u001b[0;32m    125\u001b[0m div \u001b[39m=\u001b[39m (num \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mif\u001b[39;00m endpoint \u001b[39melse\u001b[39;00m num\n\u001b[0;32m    127\u001b[0m \u001b[39m# Convert float/complex array scalars to float, gh-3504\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[39m# and make sure one can use variables that have an __array_interface__, gh-6634\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m start \u001b[39m=\u001b[39m asanyarray(start) \u001b[39m*\u001b[39;49m \u001b[39m1.0\u001b[39;49m\n\u001b[0;32m    130\u001b[0m stop  \u001b[39m=\u001b[39m asanyarray(stop)  \u001b[39m*\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[0;32m    132\u001b[0m dt \u001b[39m=\u001b[39m result_type(start, stop, \u001b[39mfloat\u001b[39m(num))\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U5'), dtype('float64')) -> None"
     ]
    }
   ],
   "source": [
    "from fairlearn.metrics import demographic_parity_difference\n",
    "\n",
    "# Attribut protégé\n",
    "protected_attribute = 'gender'\n",
    "\n",
    "# Définir la caractéristique d'intérêt et créer une grille de valeurs à analyser\n",
    "feature_of_interest = 'income'\n",
    "feature_values = np.linspace(data_df[feature_of_interest].min(), data_df[feature_of_interest].max(), num=20)\n",
    "\n",
    "# Initialiser les listes pour stocker les mesures d'équité et l'exactitude du modèle\n",
    "mesures_equite = []\n",
    "accuracies = []\n",
    "\n",
    "# Itérer sur les valeurs de la caractéristique et calculer les mesures d'équité\n",
    "for value in feature_values:\n",
    "    # Modifier le jeu de données pour fixer la caractéristique à la valeur actuelle\n",
    "    modified_X_test = X_test.copy()\n",
    "    modified_X_test[feature_of_interest] = value\n",
    "    \n",
    "    # Faire des prédictions sur le jeu de données modifié\n",
    "    modified_y_pred = pipeline.predict(modified_X_test)\n",
    "    \n",
    "    # Calculer la mesure d'équité (Différence de parité démographique)\n",
    "    mesure_equite = demographic_parity_difference(y_test, modified_y_pred, sensitive_features=X_test[protected_attribute])\n",
    "    \n",
    "    # Calculer l'exactitude du modèle\n",
    "    accuracy = accuracy_score(y_test, modified_y_pred)\n",
    "    \n",
    "    # Ajouter la mesure d'équité et l'exactitude aux listes respectives\n",
    "    mesures_equite.append(mesure_equite)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Tracer le Fairness Partial Dependence Plot (FPDP)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(feature_values, mesures_equite, label='Mesure d\\'Équité (DPD)', marker='o')\n",
    "plt.plot(feature_values, accuracies, label='Exactitude du Modèle', marker='x')\n",
    "plt.xlabel(feature_of_interest)\n",
    "plt.ylabel('Mesure d\\'Équité / Exactitude')\n",
    "plt.title('Fairness Partial Dependence Plot')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
